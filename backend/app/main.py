# -*- coding: utf-8 -*-
from typing import List, Optional, Dict
import time
import asyncio
import concurrent.futures
from pathlib import Path
import os
import sys

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë˜ëŠ” backend ë””ë ‰í† ë¦¬ì— ìˆì„ ìˆ˜ ìˆìŒ)
env_path = Path(__file__).parent.parent.parent / ".env"  # í”„ë¡œì íŠ¸ ë£¨íŠ¸
if not env_path.exists():
    env_path = Path(__file__).parent.parent / ".env"  # backend ë””ë ‰í† ë¦¬
if env_path.exists():
    load_dotenv(env_path)
    print(f"[Config] .env íŒŒì¼ ë¡œë“œë¨: {env_path}")

# ì„œë¹„ìŠ¤ ëª¨ë“ˆ import
from app.services.keyword_extractor import extract_keywords
from app.services.emotion_classifier import classify_emotion
from app.services.poem_generator import generate_poem_from_keywords
from app.services.poem_model_loader import _load_poem_model

# í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ import (koGPT2 + LoRA ë“±)
backend_path = Path(__file__).parent.parent
sys.path.insert(0, str(backend_path))
try:
    from use_trained_model import load_trained_model, generate_poem_from_prose
    HAS_TRAINED_MODEL = True
except ImportError:
    HAS_TRAINED_MODEL = False
    print("âš ï¸ í•™ìŠµëœ ëª¨ë¸ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Poem Generation API",
    description="SOLAR ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹œ ìƒì„± API (Colab GPU ì§€ì›)",
    version="1.0.0",
)

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],        # ëª¨ë“  Origin í—ˆìš© (ê°œë°œìš©)
    allow_credentials=True,
    allow_methods=["*"],        # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],        # ëª¨ë“  í—¤ë” í—ˆìš©
)

@app.get("/health")
async def health():
    return {"status": "ok"}

# OPTIONS ìš”ì²­ ëª…ì‹œì  ì²˜ë¦¬ (CORS preflight)
@app.options("/{full_path:path}")
async def options_handler(full_path: str):
    """CORS preflight ìš”ì²­ ì²˜ë¦¬"""
    from fastapi.responses import Response
    return Response(
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS, HEAD, PATCH",
            "Access-Control-Allow-Headers": "*",
            "Access-Control-Max-Age": "3600",
        },
    )


@app.on_event("startup")
async def startup_event():
    """
    ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤.
    - ì½”ë©ì—ì„œëŠ” ì²« ìš”ì²­ ì‹œ ë¡œë”©(ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ê¸¸ê¸° ë•Œë¬¸)
    - ë¡œì»¬/ì„œë²„ í™˜ê²½ì—ì„œëŠ” ì‚¬ì „ ë¡œë”©ìœ¼ë¡œ ì²« ìš”ì²­ ì§€ì—° ìµœì†Œí™”
    """
    is_colab = os.path.exists("/content")

    if is_colab:
        print("\n" + "=" * 80)
        print("ğŸŒ ì½”ë© í™˜ê²½ ê°ì§€: ëª¨ë¸ ì‚¬ì „ ë¡œë”© ê±´ë„ˆëœ€")
        print("=" * 80)
        print("ğŸ’¡ ì²« ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ì´ ë¡œë“œë©ë‹ˆë‹¤.")
        print("   (ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— 5-10ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        print("=" * 80 + "\n")
        return

    print("\n" + "=" * 80)
    print("ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘: ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹œì‘...")
    print("=" * 80)

    try:
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            await loop.run_in_executor(executor, _load_poem_model)
        print("=" * 80)
        print("âœ… ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ! ì²« ìš”ì²­ë¶€í„° ë¹ ë¥´ê²Œ ì‘ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("=" * 80 + "\n")
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹¤íŒ¨: {e}")
        print("   (ì²« ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.)\n")
        import traceback
        traceback.print_exc()


# ============================
# Pydantic ëª¨ë¸ ì •ì˜
# ============================

class PoemRequest(BaseModel):
    text: str
    lines: Optional[int] = None                 # ì¤„ ìˆ˜ (í–‰)
    mood: Optional[str] = None                  # ë¶„ìœ„ê¸° (ì”ì”/ë‹´ë‹´/ì“¸ì“¸)
    required_keywords: Optional[List[str]] = None  # í•„ìˆ˜ í‚¤ì›Œë“œ
    banned_words: Optional[List[str]] = None       # ê¸ˆì¹™ì–´
    use_rhyme: Optional[bool] = False           # ìš´ìœ¨ ì‚¬ìš© ì—¬ë¶€
    acrostic: Optional[str] = None              # ì•„í¬ë¡œìŠ¤í‹±
    model_type: Optional[str] = None            # "solar" ë˜ëŠ” "kogpt2"
    use_trained_model: Optional[bool] = False   # í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
    trained_model_path: Optional[str] = None    # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    use_gemini_improvement: Optional[bool] = True  # Geminië¡œ ì‹œ ê°œì„  ì—¬ë¶€


class PoemResponse(BaseModel):
    keywords: List[str]
    emotion: str
    emotion_confidence: float
    poem: str
    success: bool
    message: Optional[str] = None


class EmotionAnalysisRequest(BaseModel):
    poems: List[Dict]  # ì‹œ ëª©ë¡ (emotion, createdAt ë“± í¬í•¨)


class EmotionAnalysisResponse(BaseModel):
    story: str
    summary: str
    emoji: str
    message: str
    success: bool


# ============================
# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================

@app.get("/")
def root():
    """ë£¨íŠ¸ ê²½ë¡œ - API ì •ë³´ ë°˜í™˜"""
    return {
        "message": "Poem Generation API",
        "service": "siot-OSS",
        "endpoints": {
            "health": "/health",
            "generate_poem": "/api/poem/generate",
            "analyze_emotion": "/api/emotion/analyze-cute",
        },
        "docs": "/docs",
    }


@app.get("/favicon.ico")
def favicon():
    """favicon ìš”ì²­ ì²˜ë¦¬ (404 ë°©ì§€)"""
    from fastapi.responses import Response
    return Response(status_code=204)  # No Content


@app.get("/health")
def health():
    from app.services.poem_config import MODEL_TYPE, GEN_MODEL_ID
    from app.services.poem_model_loader import _is_gpu, _device_info

    device_info = _device_info()
    is_gpu = _is_gpu()
    model_display = f"{MODEL_TYPE.upper()}" + (f" (GPU: {device_info})" if is_gpu else " (CPU)")

    return {
        "ok": True,
        "service": "poem",
        "model_type": MODEL_TYPE,
        "model_id": GEN_MODEL_ID,
        "device": device_info,
        "has_gpu": is_gpu,
        "model": model_display,
    }


# ============================
# ì‹œ ìƒì„± ì—”ë“œí¬ì¸íŠ¸
# ============================

@app.post("/api/poem/generate", response_model=PoemResponse)
async def generate_poem_from_text(request: PoemRequest):
    """
    ì‚¬ìš©ìì˜ ì¼ìƒê¸€ì„ ë°›ì•„:
      1) í‚¤ì›Œë“œ ì¶”ì¶œ (TF-IDF)
      2) ê°ì • ë¶„ë¥˜ (XNLI ì œë¡œìƒ· ê¸°ë°˜)
      3) ì‹œ ìƒì„± (SOLAR / koGPT2 / í•™ìŠµ ëª¨ë¸)
      4) (í•„ìš” ì‹œ) ë²ˆì—­Â·ê°œì„ 
    ì„ ìˆ˜í–‰í•œ ë’¤ ì‹œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    t0 = time.time()
    print("\n" + "=" * 80)
    print("[API] /api/poem/generate ì§„ì…")

    # 0) ìš”ì²­ ê²€ì¦
    if not request.text or not request.text.strip():
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    text = request.text.strip()
    print(f"[API] ì…ë ¥ ê¸¸ì´: {len(text)}ì")

    # 1) í‚¤ì›Œë“œ ì¶”ì¶œ
    print("[API] 1ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘...")
    keywords = extract_keywords(text, max_keywords=10)
    print(f"[API] âœ“ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {keywords}")
    print("=" * 60)
    print("ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ:", keywords)
    print("=" * 60)

    # 2) ê°ì • ë¶„ë¥˜
    print("[API] 2ë‹¨ê³„: ê°ì • ë¶„ë¥˜ ì‹œì‘...")
    emo = classify_emotion(text)
    emotion = emo.get("emotion", "ì¤‘ë¦½")
    default_mood = emo.get("mood", "ë‹´ë‹´í•œ")
    confidence = float(emo.get("confidence", 0.0))

    mood = request.mood if request.mood else default_mood
    lines = request.lines if request.lines else 4

    print(f"[API] âœ“ ê°ì • ë¶„ë¥˜ ì™„ë£Œ: ê°ì •={emotion}, ë¶„ìœ„ê¸°={mood}, ì‹ ë¢°ë„={confidence:.3f}")
    print("=" * 60)
    print("ğŸ’­ ê°ì • ë¶„ì„ ê²°ê³¼:")
    print(f"   - ê°ì •: {emotion}")
    print(f"   - ë¶„ìœ„ê¸°: {mood} (ì‚¬ìš©ì ì§€ì •: {request.mood is not None})")
    print(f"   - ì‹ ë¢°ë„: {confidence:.3f}")
    print(f"   - ì¤„ ìˆ˜: {lines}")
    if request.required_keywords:
        print(f"   - í•„ìˆ˜ í‚¤ì›Œë“œ: {request.required_keywords}")
    if request.banned_words:
        print(f"   - ê¸ˆì¹™ì–´: {request.banned_words}")
    if request.use_rhyme:
        print("   - ìš´ìœ¨ ì‚¬ìš©: ì˜ˆ")
    if request.acrostic:
        print(f"   - ì•„í¬ë¡œìŠ¤í‹±: {request.acrostic}")
    print("=" * 60)

    # í•„ìˆ˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    final_keywords = keywords.copy()
    if request.required_keywords:
        for kw in request.required_keywords:
            if kw not in final_keywords:
                final_keywords.insert(0, kw)

    # 3) ì‹œ ìƒì„± (ê¸°ë³¸ ëª¨ë¸ or í•™ìŠµëœ ëª¨ë¸)
    print("[API] 3ë‹¨ê³„: ì‹œ ìƒì„± ì‹œì‘...", flush=True)

    use_trained = request.use_trained_model and HAS_TRAINED_MODEL
    trained_model_path = request.trained_model_path

    # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ ìë™ íƒìƒ‰
    if use_trained and not trained_model_path:
        trained_models_dir = backend_path / "trained_models"
        if trained_models_dir.exists():
            model_folders = [
                f
                for f in trained_models_dir.iterdir()
                if f.is_dir()
                and "20251109_08" in f.name
                and "kogpt2" in f.name.lower()
            ]
            if model_folders:
                trained_model_path = str(
                    sorted(model_folders, key=lambda x: x.name, reverse=True)[0]
                )
                print(f"[API] ìë™ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ ì°¾ìŒ: {trained_model_path}", flush=True)
            else:
                print("[API] âš ï¸ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©", flush=True)
                use_trained = False
        else:
            print("[API] âš ï¸ trained_models í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©", flush=True)
            use_trained = False

    loop = asyncio.get_event_loop()

    try:
        with concurrent.futures.ThreadPoolExecutor() as executor:
            if use_trained and trained_model_path:
                # =============================
                # 3-A) í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš© (koGPT2 + LoRA ë“±)
                # =============================
                print("[API] í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš© ëª¨ë“œ", flush=True)

                def generate_with_trained_model():
                    # ìºì‹œëœ ëª¨ë¸ ì‚¬ìš© (ì—†ìœ¼ë©´ ë¡œë“œ)
                    if (
                        not hasattr(generate_with_trained_model, "_tokenizer")
                        or not hasattr(generate_with_trained_model, "_model")
                        or not hasattr(generate_with_trained_model, "_device")
                        or getattr(
                            generate_with_trained_model, "_model_path", None
                        )
                        != trained_model_path
                    ):
                        print("[API] í•™ìŠµëœ ëª¨ë¸ ë¡œë”© ì¤‘...", flush=True)
                        tokenizer, model, device = load_trained_model(trained_model_path)
                        generate_with_trained_model._tokenizer = tokenizer
                        generate_with_trained_model._model = model
                        generate_with_trained_model._device = device
                        generate_with_trained_model._model_path = trained_model_path
                        print("[API] í•™ìŠµëœ ëª¨ë¸ ë¡œë”© ì™„ë£Œ", flush=True)

                    # ì‚°ë¬¸ ì§ì ‘ ì…ë ¥ â†’ ì‹œ ìƒì„±
                    raw_poem = generate_poem_from_prose(
                        text,
                        generate_with_trained_model._tokenizer,
                        generate_with_trained_model._model,
                        generate_with_trained_model._device,
                        max_new_tokens=150,
                    )

                    # Gemini ê°œì„  ì˜µì…˜ ì²´í¬
                    has_prompt_options = (
                        (request.lines is not None and request.lines != 4)
                        or (request.mood is not None and request.mood.strip() != "")
                        or (
                            request.required_keywords is not None
                            and len(request.required_keywords) > 0
                        )
                        or (
                            request.banned_words is not None
                            and len(request.banned_words) > 0
                        )
                        or (request.use_rhyme is True)
                        or (
                            request.acrostic is not None
                            and request.acrostic.strip() != ""
                        )
                    )

                    print(
                        "[API] í”„ë¡¬í”„íŠ¸ ì˜µì…˜ ì²´í¬:",
                        f"lines={request.lines}, mood={request.mood}, "
                        f"required_keywords={request.required_keywords}, banned_words={request.banned_words}, "
                        f"use_rhyme={request.use_rhyme}, acrostic={request.acrostic}",
                        flush=True,
                    )
                    print(
                        f"[API] has_prompt_options={has_prompt_options}, "
                        f"use_gemini_improvement={request.use_gemini_improvement}",
                        flush=True,
                    )

                    from app.main import improve_poem_with_gemini  # ìˆœí™˜ import ë°©ì§€ìš© ì§€ì—° import

                    if has_prompt_options and request.use_gemini_improvement is not False:
                        try:
                            print("[API] Geminië¡œ ì‹œ ê°œì„  ì‹œì‘", flush=True)
                            improved_poem = improve_poem_with_gemini(
                                raw_poem,
                                text,
                                lines=request.lines,
                                mood=request.mood,
                                required_keywords=request.required_keywords,
                                banned_words=request.banned_words,
                                use_rhyme=request.use_rhyme,
                                acrostic=request.acrostic,
                            )
                            if improved_poem and improved_poem != raw_poem:
                                print(
                                    f"[API] âœ“ Gemini ê°œì„  ì™„ë£Œ: ì›ë³¸ {len(raw_poem)}ì â†’ ê°œì„  {len(improved_poem)}ì",
                                    flush=True,
                                )
                                return improved_poem
                            else:
                                print(
                                    "[API] âš ï¸ Gemini ê°œì„  ê²°ê³¼ê°€ ì›ë³¸ê³¼ ë™ì¼í•˜ê±°ë‚˜ ë¹„ì–´ìˆìŒ. ì›ë³¸ ë°˜í™˜",
                                    flush=True,
                                )
                                return raw_poem
                        except Exception as e:
                            print(f"[API] âŒ Gemini ì‹œ ê°œì„  ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}", flush=True)
                            import traceback

                            traceback.print_exc()
                            return raw_poem
                    else:
                        if has_prompt_options:
                            print(
                                "[API] í”„ë¡¬í”„íŠ¸ ì˜µì…˜ì€ ìˆìœ¼ë‚˜ Gemini ê°œì„  ë¹„í™œì„±í™”",
                                flush=True,
                            )
                        else:
                            print(
                                "[API] í”„ë¡¬í”„íŠ¸ ì˜µì…˜ ì—†ìŒ â†’ Gemini ê°œì„  ìƒëµ (ì›ë³¸ ì‹œ ë°˜í™˜)",
                                flush=True,
                            )
                        return raw_poem

                poem = await asyncio.wait_for(
                    loop.run_in_executor(executor, generate_with_trained_model),
                    timeout=300.0,
                )
            else:
                # =============================
                # 3-B) ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (SOLAR / koGPT2)
                #  â†’ generate_poem_from_keywords ì•ˆì—ì„œ
                #     í”„ë¡¬í”„íŠ¸ êµ¬ì„± + SOLAR í˜¸ì¶œ + í›„ì²˜ë¦¬ + (í•„ìš” ì‹œ ë²ˆì—­)ê¹Œì§€ ìˆ˜í–‰
                # =============================
                print(
                    "[API] ê¸°ë³¸ ëª¨ë¸ë¡œ ì‹œ ìƒì„± ì¤‘... (max_new_tokens=80)",
                    flush=True,
                )
                poem = await asyncio.wait_for(
                    loop.run_in_executor(
                        executor,
                        generate_poem_from_keywords,
                        final_keywords,
                        mood,
                        lines,
                        80,
                        text,
                        request.banned_words,
                        request.use_rhyme,
                        request.acrostic,
                        request.model_type,  # "solar" (Colab) ë˜ëŠ” "kogpt2"
                    ),
                    timeout=300.0,
                )

        print(f"[API] âœ“ ì‹œ ìƒì„± ì™„ë£Œ (ê¸¸ì´ {len(poem)}ì)", flush=True)
    except asyncio.TimeoutError:
        print("[API] âŒ íƒ€ì„ì•„ì›ƒ(>300s)", flush=True)
        raise HTTPException(
            status_code=504,
            detail=(
                "ì‹œ ìƒì„± ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤ (5ë¶„). "
                "ì²« ìš”ì²­ì€ ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            ),
        )
    except Exception as e:
        error_type = type(e).__name__
        msg = str(e) or "ì‹œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        print(f"[API] âŒ ìƒì„± ì˜ˆì™¸: {error_type}: {msg}")
        import traceback

        print("[API] ì „ì²´ íŠ¸ë ˆì´ìŠ¤ë°±:")
        traceback.print_exc()

        if "ë©”ëª¨ë¦¬" in msg or "memory" in msg.lower() or "cuda" in msg.lower():
            detail_msg = f"GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë˜ëŠ” CUDA ì˜¤ë¥˜ì…ë‹ˆë‹¤. {msg[:200]}"
        elif "ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in msg or "ë¹„ì–´ìˆìŠµë‹ˆë‹¤" in msg:
            detail_msg = f"ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. {msg[:200]}"
        else:
            detail_msg = f"ì‹œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {msg[:200]}"

        raise HTTPException(status_code=500, detail=detail_msg)

    # 4) ìµœì¢… ê²€ì¦ (ì•„ì£¼ ê´€ëŒ€)
    poem_clean = (poem or "").strip()
    if not poem_clean:
        print("[API] âŒ ìµœì¢… ê²°ê³¼ ë¹ˆ ë¬¸ìì—´")
        raise HTTPException(
            status_code=500,
            detail="ì‹œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒì„±ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
        )

    korean_chars = sum(1 for c in poem_clean if ord("ê°€") <= ord(c) <= ord("í£"))
    print(f"[API] ìµœì¢… ê²€ì¦: ê¸¸ì´={len(poem_clean)}ì, í•œê¸€ë¬¸ì={korean_chars}ì")
    if korean_chars < 3 and len(poem_clean) < 3:
        raise HTTPException(
            status_code=500,
            detail="ì‹œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒì„±ëœ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.",
        )

    print(f"[API] ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {time.time() - t0:.2f}s")
    print("=" * 80)

    return PoemResponse(
        keywords=keywords,
        emotion=emotion,
        emotion_confidence=confidence,
        poem=poem_clean,
        success=True,
        message="ì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
    )


# ============================
# Gemini ê¸°ë°˜ ì‹œ ê°œì„  / ê°ì • ìŠ¤í† ë¦¬
# ============================

def improve_poem_with_gemini(
    raw_poem: str,
    original_prose: str = "",
    lines: Optional[int] = None,
    mood: Optional[str] = None,
    required_keywords: Optional[List[str]] = None,
    banned_words: Optional[List[str]] = None,
    use_rhyme: Optional[bool] = False,
    acrostic: Optional[str] = None,
) -> str:
    """
    Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ koGPT2ë¡œ ìƒì„±í•œ ì‹œë¥¼ ê°œì„ í•©ë‹ˆë‹¤.
    (SOLAR + ë²ˆì—­ íŒŒì´í”„ë¼ì¸ê³¼ëŠ” ë…ë¦½ì ì¸ ì˜µì…˜ ê¸°ëŠ¥)
    """
    try:
        import google.generativeai as genai

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("[Gemini] âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›ë³¸ ì‹œ ë°˜í™˜")
            return raw_poem

        genai.configure(api_key=api_key)

        try:
            print("[Gemini] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸ ì¤‘...", flush=True)
            available_models = []
            for model_info in genai.list_models():
                if "generateContent" in model_info.supported_generation_methods:
                    available_models.append(model_info.name)

            print(f"[Gemini] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ {len(available_models)}ê°œ ë°œê²¬", flush=True)

            preferred_models = [
                "models/gemini-2.5-flash",
                "models/gemini-2.5-flash-lite-preview-06-17",
                "models/gemini-1.5-flash",
                "models/gemini-1.5-pro",
                "models/gemini-pro",
            ]

            model = None
            selected_model_name = None
            for model_name in preferred_models:
                if model_name in available_models:
                    try:
                        model = genai.GenerativeModel(model_name)
                        selected_model_name = model_name
                        print(
                            f"[Gemini] ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}",
                            flush=True,
                        )
                        break
                    except Exception as e:
                        print(
                            f"[Gemini] ëª¨ë¸ {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}",
                            flush=True,
                        )
                        continue

            if model is None and available_models:
                selected_model_name = available_models[0]
                model = genai.GenerativeModel(selected_model_name)
                print(
                    f"[Gemini] ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©: {selected_model_name}",
                    flush=True,
                )
            elif model is None:
                print("[Gemini] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ì‹œ ë°˜í™˜", flush=True)
                return raw_poem
        except Exception as e:
            print(f"[Gemini] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}, ì›ë³¸ ì‹œ ë°˜í™˜", flush=True)
            import traceback

            traceback.print_exc()
            return raw_poem

        # ì˜µì…˜ í…ìŠ¤íŠ¸ êµ¬ì„±
        option_parts = []
        if lines is not None and lines != 4:
            option_parts.append(f"- ì •í™•íˆ {lines}ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
        if mood and mood.strip():
            option_parts.append(
                f"- ë¶„ìœ„ê¸°: {mood.strip()} (ì´ ë¶„ìœ„ê¸°ë¥¼ ì‹œì— ë°˜ì˜í•´ì£¼ì„¸ìš”)"
            )
        if required_keywords:
            kw_str = ", ".join(required_keywords)
            option_parts.append(
                f"- í•„ìˆ˜ í‚¤ì›Œë“œ: {kw_str} (ë°˜ë“œì‹œ ì´ í‚¤ì›Œë“œë“¤ì„ ì‹œì— í¬í•¨í•´ì£¼ì„¸ìš”)"
            )
        if banned_words:
            banned_str = ", ".join(banned_words)
            option_parts.append(
                f"- ê¸ˆì§€ ë‹¨ì–´: {banned_str} (ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”)"
            )
        if use_rhyme:
            option_parts.append(
                "- ìš´ìœ¨ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ë¹„ìŠ·í•œ ë°œìŒì´ë‚˜ ë°˜ë³µë˜ëŠ” ì†Œë¦¬ë¡œ ë¦¬ë“¬ê°ì„ ì£¼ì„¸ìš”)"
            )
        if acrostic and acrostic.strip():
            acrostic_chars = " ".join(list(acrostic.strip()))
            option_parts.append(
                f"- ë‘ë¬¸ì ì‹œ: ê° ì¤„ì˜ ì²« ê¸€ìê°€ '{acrostic_chars}' ìˆœì„œëŒ€ë¡œ ì˜¤ë„ë¡ í•´ì£¼ì„¸ìš” "
                f"(ì´ {len(acrostic.strip())}ì¤„)"
            )

        options_text = "\n".join(option_parts) if option_parts else ""

        if options_text:
            print(
                f"[Gemini] í”„ë¡¬í”„íŠ¸ ì˜µì…˜ ì ìš©: {len(option_parts)}ê°œ ì˜µì…˜",
                flush=True,
            )
            for i, opt in enumerate(option_parts, 1):
                print(f"[Gemini]   {i}. {opt}", flush=True)
        else:
            print("[Gemini] í”„ë¡¬í”„íŠ¸ ì˜µì…˜ ì—†ìŒ (ê¸°ë³¸ ê°œì„ ë§Œ ìˆ˜í–‰)", flush=True)

        prompt = f"""ë‹¤ìŒì€ AIê°€ ìƒì„±í•œ í•œêµ­ì–´ ì‹œì…ë‹ˆë‹¤. ì´ ì‹œë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”.

ì›ë³¸ ì‚°ë¬¸ (ì°¸ê³ ìš©):
{original_prose[:200] if original_prose else "ì—†ìŒ"}

ìƒì„±ëœ ì‹œ:
{raw_poem}

ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
1. ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±° (ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ ë¬¸ì¥, ì„¤ëª…ë¬¸ ë“±)
2. "ì‹œ:", "ì‚°ë¬¸:" ê°™ì€ í”„ë¡¬í”„íŠ¸ íŒ¨í„´ ì œê±°
3. ì ì ˆí•œ ì¤„ë°”ê¿ˆ ìœ ì§€ (ë¬¸ì¥ ëê³¼ ì‰¼í‘œ ë’¤)
4. ì‹œì  í‘œí˜„ ê°œì„  (ìì—°ìŠ¤ëŸ½ê³  ì•„ë¦„ë‹¤ìš´ í‘œí˜„ìœ¼ë¡œ ë‹¤ë“¬ê¸°)
{f"5. ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:\n{options_text}" if options_text else ""}

ì¤‘ìš”: ì‹œì˜ ì£¼ì œì™€ í•µì‹¬ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜, í‘œí˜„ì„ ë” ì‹œë‹µê²Œ ê°œì„ í•´ì£¼ì„¸ìš”.

ê°œì„ ëœ ì‹œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ì‹œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

        print(
            f"[Gemini] í”„ë¡¬í”„íŠ¸ ì „ì†¡ ì¤‘... (ì›ë³¸ ì‹œ ê¸¸ì´: {len(raw_poem)}ì)",
            flush=True,
        )
        response = model.generate_content(prompt)

        improved_poem = ""
        if hasattr(response, "text"):
            improved_poem = response.text.strip()
        elif getattr(response, "candidates", None):
            c0 = response.candidates[0]
            if getattr(c0, "content", None) and getattr(c0.content, "parts", None):
                improved_poem = "".join(
                    [p.text for p in c0.content.parts if hasattr(p, "text")]
                ).strip()

        print(f"[Gemini] ì‘ë‹µ ë°›ìŒ: {len(improved_poem)}ì", flush=True)
        if improved_poem:
            print(
                f"[Gemini] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 100ì): {improved_poem[:100]}",
                flush=True,
            )

        if improved_poem and len(improved_poem) > 10:
            print(
                f"[Gemini] ì‹œ ê°œì„  ì™„ë£Œ: {len(raw_poem)}ì â†’ {len(improved_poem)}ì",
                flush=True,
            )
            return improved_poem
        else:
            print(
                f"[Gemini] ê°œì„  ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ ({len(improved_poem)}ì). ì›ë³¸ ì‹œ ë°˜í™˜",
                flush=True,
            )
            return raw_poem

    except Exception as e:
        print(f"[Gemini] ì‹œ ê°œì„  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        return raw_poem


def analyze_emotions_cutely(poems: List[Dict]) -> Dict[str, str]:
    """
    Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì • ë°ì´í„°ë¥¼ ê·€ì—¬ìš´ ìŠ¤í† ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    try:
        import google.generativeai as genai

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("[Gemini] âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "story": "ê°ì • ë¶„ì„ì„ ìœ„í•´ Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
                "summary": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "emoji": "ğŸ”‘",
                "message": "ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.",
                "success": False,
            }

        genai.configure(api_key=api_key)

        try:
            available_models = []
            for model_info in genai.list_models():
                if "generateContent" in model_info.supported_generation_methods:
                    available_models.append(model_info.name)

            print(f"[Gemini] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models[:5]}")

            preferred_models = [
                "models/gemini-2.5-flash",
                "models/gemini-2.5-flash-lite-preview-06-17",
                "models/gemini-1.5-flash",
                "models/gemini-1.5-pro",
                "models/gemini-pro",
            ]

            model = None
            for model_name in preferred_models:
                if model_name in available_models:
                    try:
                        model = genai.GenerativeModel(model_name)
                        print(f"[Gemini] ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                        break
                    except Exception as e:
                        print(f"[Gemini] ëª¨ë¸ {model_name} ì‹œë„ ì‹¤íŒ¨: {e}")
                        continue

            if model is None:
                if available_models:
                    first_model = available_models[0]
                    print(f"[Gemini] ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©: {first_model}")
                    model = genai.GenerativeModel(first_model)
                else:
                    raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"[Gemini] ëª¨ë¸ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‹œë„: {e}")
            try:
                model = genai.GenerativeModel("models/gemini-2.5-flash")
            except Exception:
                try:
                    model = genai.GenerativeModel("models/gemini-1.5-flash")
                except Exception:
                    raise Exception(f"ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")

        # ê°ì • ë°ì´í„° ì§‘ê³„
        emotion_data: Dict[str, Dict[str, int]] = {}
        for poem in poems:
            if not poem.get("emotion") or not poem.get("createdAt"):
                continue
            emotion = poem["emotion"]
            date = poem["createdAt"][:10]
            if date not in emotion_data:
                emotion_data[date] = {}
            emotion_data[date][emotion] = emotion_data[date].get(emotion, 0) + 1

        emotion_counts: Dict[str, int] = {}
        for poem in poems:
            if poem.get("emotion"):
                emotion = poem["emotion"]
                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

        prompt = f"""ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°ì • ë°ì´í„°ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ê°ì • ë°ì´í„°:
{emotion_data}

ê°ì •ë³„ ê°œìˆ˜:
{emotion_counts}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

1. ê°ì • ì¶”ì´ ìŠ¤í† ë¦¬ (100-150ì): ë‚ ì§œë³„ ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
2. ê°ì • ìš”ì•½ (50-80ì): ì „ì²´ì ì¸ ê°ì • íŒ¨í„´ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
3. ëŒ€í‘œ ì´ëª¨ì§€: ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ ê°ì •ì— ë§ëŠ” ì´ëª¨ì§€ í•˜ë‚˜
4. ë”°ëœ»í•œ ë©”ì‹œì§€ (30-50ì): ì‚¬ìš©ìì—ê²Œ ì „í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì‹œì§€

ì£¼ì˜ì‚¬í•­:
- ì–´ë¦°ì•„ì´ì—ê²Œ í•˜ëŠ” ë§íˆ¬ë‚˜ ê³¼ë„í•˜ê²Œ ê·€ì—¬ìš´ í‘œí˜„ì€ í”¼í•´ì£¼ì„¸ìš”
- ìì—°ìŠ¤ëŸ½ê³  ì„±ìˆ™í•œ í†¤ì„ ìœ ì§€í•´ì£¼ì„¸ìš”
- ë”°ëœ»í•˜ì§€ë§Œ ì „ë¬¸ì ì¸ ëŠë‚Œì„ ì£¼ì„¸ìš”

í˜•ì‹:
ìŠ¤í† ë¦¬: [ì—¬ê¸°ì— ìŠ¤í† ë¦¬]
ìš”ì•½: [ì—¬ê¸°ì— ìš”ì•½]
ì´ëª¨ì§€: [ì—¬ê¸°ì— ì´ëª¨ì§€]
ë©”ì‹œì§€: [ì—¬ê¸°ì— ë©”ì‹œì§€]
"""

        response = model.generate_content(prompt)
        result_text = response.text

        story = ""
        summary = ""
        emoji = "ğŸ’­"
        message = ""

        for line in result_text.split("\n"):
            line = line.strip()
            if line.startswith("ìŠ¤í† ë¦¬:"):
                story = line.replace("ìŠ¤í† ë¦¬:", "").strip()
            elif line.startswith("ìš”ì•½:"):
                summary = line.replace("ìš”ì•½:", "").strip()
            elif line.startswith("ì´ëª¨ì§€:"):
                emoji = line.replace("ì´ëª¨ì§€:", "").strip()
            elif line.startswith("ë©”ì‹œì§€:"):
                message = line.replace("ë©”ì‹œì§€:", "").strip()

        if not story:
            story = result_text[:150] if result_text else "ê°ì • ë°ì´í„°ë¥¼ ë¶„ì„í–ˆì–´ìš”!"
        if not summary:
            summary = "ê°ì • ë³€í™”ë¥¼ í™•ì¸í–ˆì–´ìš”."
        if not message:
            message = "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í•˜ì…¨ì–´ìš”!"

        return {
            "story": story,
            "summary": summary,
            "emoji": emoji,
            "message": message,
            "success": True,
        }

    except Exception as e:
        print(f"[Gemini] âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        return {
            "story": "ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "summary": "ì˜¤ë¥˜ ë°œìƒ",
            "emoji": "ğŸ˜¢",
            "message": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "success": False,
        }


@app.post("/api/emotion/analyze-cute", response_model=EmotionAnalysisResponse)
async def analyze_emotions_cutely_endpoint(request: EmotionAnalysisRequest):
    """
    ê°ì • ë°ì´í„°ë¥¼ ë°›ì•„ì„œ Gemini APIë¡œ ê·€ì—¬ìš´ ìŠ¤í† ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    print("\n" + "=" * 80)
    print("[API] /api/emotion/analyze-cute ì§„ì…")
    print(f"[API] ì‹œ ê°œìˆ˜: {len(request.poems)}ê°œ")

    if not request.poems:
        raise HTTPException(status_code=400, detail="ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    result = analyze_emotions_cutely(request.poems)

    print("[API] âœ“ ê°ì • ë¶„ì„ ì™„ë£Œ")
    print("=" * 80)

    return EmotionAnalysisResponse(**result)